{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2B07osxcrvEv"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JywBpOzLrvEw"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Import using 'tf.keras'\n",
        "backend = tf.keras.backend\n",
        "layers = tf.keras.layers\n",
        "models = tf.keras.models"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GMrkXZHYrvEx"
      },
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=176):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "seed_everything(30)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "E4kEQBBnrvEx"
      },
      "cell_type": "code",
      "source": [
        "base_dir = \"../input/osic-pulmonary-fibrosis-progression\"\n",
        "BATCH_SIZE=128"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TPOizdOnrvEx",
        "outputId": "00339cdb-ff72-49ef-b1a4-43f7b7ed7ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "tr = pd.read_csv(\"train.csv\")\n",
        "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
        "chunk = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# add info\n",
        "sub = pd.read_csv(\"sample_submission.csv\")\n",
        "#print(sub.head(5), '\\n')\n",
        "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
        "#print(sub.head(5), '\\n')\n",
        "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
        "#print(sub.head(5), '\\n')\n",
        "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
        "#print(sub.head(5), '\\n')\n",
        "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")\n",
        "print(sub.head(5), '\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Patient  Weeks  Confidence  \\\n",
            "0  ID00419637202311204720264    -12         100   \n",
            "1  ID00421637202311550012437    -12         100   \n",
            "2  ID00422637202311677017371    -12         100   \n",
            "3  ID00423637202312137826377    -12         100   \n",
            "4  ID00426637202313170790466    -12         100   \n",
            "\n",
            "                    Patient_Week   FVC    Percent  Age   Sex SmokingStatus  \n",
            "0  ID00419637202311204720264_-12  3020  70.186855   73  Male     Ex-smoker  \n",
            "1  ID00421637202311550012437_-12  2739  82.045291   68  Male     Ex-smoker  \n",
            "2  ID00422637202311677017371_-12  1930  76.672493   73  Male     Ex-smoker  \n",
            "3  ID00423637202312137826377_-12  3294  79.258903   72  Male     Ex-smoker  \n",
            "4  ID00426637202313170790466_-12  2925  71.824968   73  Male  Never smoked   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tAySjmXGrvEy",
        "outputId": "8fc6150f-5162-4733-a867-e443c03f2315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# combine training, validation, and test data into one dataframe with new column 'WHERE' specifying train, validation, or test\n",
        "tr['WHERE'] = 'train'\n",
        "chunk['WHERE'] = 'val'\n",
        "sub['WHERE'] = 'test'\n",
        "data = pd.concat([tr, chunk, sub])\n",
        "\n",
        "print(data.head(5))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus  \\\n",
            "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker   \n",
            "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker   \n",
            "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker   \n",
            "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker   \n",
            "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker   \n",
            "\n",
            "   WHERE  Confidence Patient_Week  \n",
            "0  train         NaN          NaN  \n",
            "1  train         NaN          NaN  \n",
            "2  train         NaN          NaN  \n",
            "3  train         NaN          NaN  \n",
            "4  train         NaN          NaN  \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0BoIZNNyrvEy",
        "outputId": "06a37b24-5cd0-45eb-95ee-6d0a5a44db9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
        "print('number of unique patients in training set: ', tr.Patient.nunique())\n",
        "print('number of unique patients in validation set: ', chunk.Patient.nunique())\n",
        "print('number of unique patients in test set: ', sub.Patient.nunique())\n",
        "print('number of unique patients in data: ', data.Patient.nunique())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
            "number of unique patients in training set:  176\n",
            "number of unique patients in validation set:  5\n",
            "number of unique patients in test set:  5\n",
            "number of unique patients in data:  176\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HIPoobagrvEy"
      },
      "cell_type": "code",
      "source": [
        "# make all test set 'min_week' = NAN\n",
        "data['min_week'] = data['Weeks']\n",
        "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
        "\n",
        "# giving each data row a min_week column that is equal to the smallest 'Weeks' for that patient id\n",
        "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TCkPbYo3rvEz"
      },
      "cell_type": "code",
      "source": [
        "# create base FVC (similar to min week)\n",
        "base = data.loc[data.Weeks == data.min_week]\n",
        "base = base[['Patient','FVC']].copy()\n",
        "base.columns = ['Patient','min_FVC']\n",
        "base['nb'] = 1\n",
        "\n",
        "# count any duplicates and only select samples with none?\n",
        "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
        "base = base[base.nb==1]\n",
        "base.drop('nb', axis=1, inplace=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WnSUlmpvrvEz"
      },
      "cell_type": "code",
      "source": [
        "# merge base and data by matching Patient numbers\n",
        "data = data.merge(base, on='Patient', how='left')\n",
        "\n",
        "# create time difference between min and current week\n",
        "data['base_week'] = data['Weeks'] - data['min_week']\n",
        "\n",
        "del base"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "h8NU1xRJrvEz",
        "outputId": "e964b509-abe3-4cf2-b632-ee381516afb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# one hot encode necessary columns\n",
        "\n",
        "COLS = ['Sex','SmokingStatus']\n",
        "FE = []  # list of column names that will be used for analysis\n",
        "for col in COLS:\n",
        "    for mod in data[col].unique():\n",
        "\n",
        "        # keep column unique column names in FE\n",
        "        FE.append(mod)\n",
        "\n",
        "        # create new column with column name and value of 0 or 1 if col==mod (i.e. Ex-smoker == Ex-smoker is value of 1\n",
        "        # and Ex-Smoker == Never smoked is value of 0)\n",
        "        data[mod] = (data[col] == mod).astype(int)\n",
        "\n",
        "print(data.head(5))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus  \\\n",
            "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker   \n",
            "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker   \n",
            "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker   \n",
            "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker   \n",
            "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker   \n",
            "\n",
            "   WHERE  Confidence Patient_Week  min_week  min_FVC  base_week  Male  Female  \\\n",
            "0  train         NaN          NaN      -4.0     2315        0.0     1       0   \n",
            "1  train         NaN          NaN      -4.0     2315        9.0     1       0   \n",
            "2  train         NaN          NaN      -4.0     2315       11.0     1       0   \n",
            "3  train         NaN          NaN      -4.0     2315       13.0     1       0   \n",
            "4  train         NaN          NaN      -4.0     2315       15.0     1       0   \n",
            "\n",
            "   Ex-smoker  Never smoked  Currently smokes  \n",
            "0          1             0                 0  \n",
            "1          1             0                 0  \n",
            "2          1             0                 0  \n",
            "3          1             0                 0  \n",
            "4          1             0                 0  \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Dy8lr_hjrvEz"
      },
      "cell_type": "code",
      "source": [
        "# normalize using min and max of each column (this creates new columns age, BASE, week, percent)\n",
        "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
        "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
        "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
        "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
        "FE += ['age','percent','week','BASE']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_UfGXwILrvEz"
      },
      "cell_type": "code",
      "source": [
        "# split into training, validation, and test\n",
        "\n",
        "tr = data.loc[data.WHERE=='train']\n",
        "chunk = data.loc[data.WHERE=='val']\n",
        "sub = data.loc[data.WHERE=='test']\n",
        "del data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mHPLqLKwrvEz",
        "outputId": "bc6342a8-3518-48a7-9389-8a83698b8bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "tr.shape, chunk.shape, sub.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1535, 22), (5, 22), (730, 22))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "KWzxdbWhrvE0"
      },
      "cell_type": "markdown",
      "source": [
        "### BASELINE NN"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "77Mqc2dErvE0"
      },
      "cell_type": "code",
      "source": [
        "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
        "\n",
        "#=============================#\n",
        "# the metric for scoring defined by the Fibrosis challenge\n",
        "def score(y_true, y_pred):\n",
        "    tf.dtypes.cast(y_true, tf.float32)\n",
        "    tf.dtypes.cast(y_pred, tf.float32)\n",
        "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
        "    fvc_pred = y_pred[:, 1]\n",
        "\n",
        "    #sigma_clip = sigma + C1\n",
        "    sigma_clip = tf.maximum(sigma, C1)\n",
        "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
        "    delta = tf.minimum(delta, C2)\n",
        "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
        "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
        "    return backend.mean(metric)\n",
        "\n",
        "#============================#\n",
        "def qloss(y_true, y_pred):\n",
        "    # Pinball loss for multiple quantiles\n",
        "    qs = [0.18394, 0.50, 0.81606]\n",
        "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
        "    e = y_true - y_pred\n",
        "    v = tf.maximum(q*e, (q-1)*e)\n",
        "    return backend.mean(v)\n",
        "\n",
        "#=============================#\n",
        "def mloss(_lambda):\n",
        "    def loss(y_true, y_pred):\n",
        "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "#=================\n",
        "\n",
        "# UNDERSTAND WHAT IS GOING ON HERE\n",
        "def make_model(nh):\n",
        "    z = layers.Input((nh,), name=\"Patient\")\n",
        "    x = layers.Dense(128, activation=\"relu\", name=\"d1\")(z)\n",
        "    x = layers.Dense(128, activation=\"relu\", name=\"d2\")(x)\n",
        "    #x = layers.Dense(64, activation=\"relu\", name=\"d3\")(x)\n",
        "    p1 = layers.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
        "    p2 = layers.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
        "    preds = layers.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1),\n",
        "                     name=\"preds\")([p1, p2])\n",
        "\n",
        "    model1 = models.Model(z, preds, name=\"CNN\")\n",
        "\n",
        "    # Define the optimizer here\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=0.1,\n",
        "        decay_steps=10000,  # Adjust decay steps as needed\n",
        "        decay_rate=0.9\n",
        "    )\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
        "\n",
        "    model1.compile(loss=mloss(0.8), optimizer=opt, metrics=[score])\n",
        "    return model1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2lwT6Ib7rvE1",
        "outputId": "01156a96-7326-48e2-d3f1-07c6e1cfbb0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "y = tr['FVC'].values\n",
        "z = tr[FE].values\n",
        "ze = sub[FE].values\n",
        "\n",
        "# number of parameters in the model (i.e. number of columns)\n",
        "nh = z.shape[1]\n",
        "print('number of columns (parameters):', nh)\n",
        "\n",
        "pe = np.zeros((ze.shape[0], 3))\n",
        "pred = np.zeros((z.shape[0], 3))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of columns (parameters): 9\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Nn4XQFB_rvE1",
        "outputId": "48fdac80-2fea-4f12-d989-5a5a78da92a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "net = make_model(nh)\n",
        "print(net.summary())\n",
        "print(net.count_params())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CNN\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Patient (InputLayer)           [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " d1 (Dense)                     (None, 128)          1280        ['Patient[0][0]']                \n",
            "                                                                                                  \n",
            " d2 (Dense)                     (None, 128)          16512       ['d1[0][0]']                     \n",
            "                                                                                                  \n",
            " p1 (Dense)                     (None, 3)            387         ['d2[0][0]']                     \n",
            "                                                                                                  \n",
            " p2 (Dense)                     (None, 3)            387         ['d2[0][0]']                     \n",
            "                                                                                                  \n",
            " preds (Lambda)                 (None, 3)            0           ['p1[0][0]',                     \n",
            "                                                                  'p2[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,566\n",
            "Trainable params: 18,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "18566\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "D3rEdqpkrvE2"
      },
      "cell_type": "code",
      "source": [
        "# K-Folds cross-validator: Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds\n",
        "\n",
        "NFOLD = 10\n",
        "kf = KFold(n_splits=NFOLD)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "D-A6KPIprvE2",
        "outputId": "019af43e-4a28-4c69-d974-a2d89440ab88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cnt = 0\n",
        "EPOCHS = 800\n",
        "\n",
        "# train data on a bunch of different split folds (NFOLD number of them)\n",
        "for tr_idx, val_idx in kf.split(z):\n",
        "\n",
        "    cnt += 1\n",
        "    print(f\"FOLD {cnt}\")\n",
        "\n",
        "    # make model for new split\n",
        "    net = make_model(nh)\n",
        "\n",
        "    # Cast input data to float32\n",
        "    net.fit(z[tr_idx].astype(np.float32), y[tr_idx].astype(np.float32),\n",
        "            batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "            validation_data=(z[val_idx].astype(np.float32), y[val_idx].astype(np.float32)),\n",
        "            verbose=0)\n",
        "\n",
        "    print(\"train\", net.evaluate(z[tr_idx].astype(np.float32), y[tr_idx].astype(np.float32), verbose=0, batch_size=BATCH_SIZE))\n",
        "    print(\"val\", net.evaluate(z[val_idx].astype(np.float32), y[val_idx].astype(np.float32), verbose=0, batch_size=BATCH_SIZE))\n",
        "    print(\"predict val...\")\n",
        "\n",
        "    pred[val_idx] = net.predict(z[val_idx].astype(np.float32), batch_size=BATCH_SIZE, verbose=0)\n",
        "    print(\"predict test...\")\n",
        "\n",
        "    # sum all the fold predictions and divide by number of folds\n",
        "    pe += net.predict(ze.astype(np.float32), batch_size=BATCH_SIZE, verbose=0) / NFOLD"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1054, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1247, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 240, in _update_step\n        self.update_step(gradient, variable)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/adam.py\", line 200, in update_step\n        variable.assign_sub((m * alpha) / (tf.sqrt(v) + self.epsilon))\n\n    ValueError: None values not supported.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1054, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 1247, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\", line 240, in _update_step\n        self.update_step(gradient, variable)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/optimizers/adam.py\", line 200, in update_step\n        variable.assign_sub((m * alpha) / (tf.sqrt(v) + self.epsilon))\n\n    ValueError: None values not supported.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_G4bju9XrvE2"
      },
      "cell_type": "code",
      "source": [
        "sigma_opt = mean_absolute_error(y, pred[:, 1])\n",
        "unc = pred[:,2] - pred[:, 0]\n",
        "sigma_mean = np.mean(unc)\n",
        "print(sigma_opt, sigma_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WoWNPfoFrvE2"
      },
      "cell_type": "code",
      "source": [
        "idxs = np.random.randint(0, y.shape[0], 100)\n",
        "plt.plot(y[idxs], label=\"ground truth\")\n",
        "plt.plot(pred[idxs, 0], label=\"q25\")\n",
        "plt.plot(pred[idxs, 1], label=\"q50\")\n",
        "plt.plot(pred[idxs, 2], label=\"q75\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WMVYIz9BrvE2"
      },
      "cell_type": "code",
      "source": [
        "print(unc.min(), unc.mean(), unc.max(), (unc>=0).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GnR9z17trvE3"
      },
      "cell_type": "code",
      "source": [
        "plt.hist(unc)\n",
        "plt.title(\"uncertainty in prediction\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfPIae5BrvE3"
      },
      "cell_type": "markdown",
      "source": [
        "### PREDICTION"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QqDzfzw2rvE3"
      },
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8X42-BCxrvE3"
      },
      "cell_type": "code",
      "source": [
        "sub['FVC1'] = 0.996*pe[:, 1]\n",
        "sub['Confidence1'] = pe[:, 2] - pe[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YpFg4_a9rvE3"
      },
      "cell_type": "code",
      "source": [
        "subm = sub[['Patient_Week','FVC','Confidence','FVC1','Confidence1']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2_ikuAFMrvE4"
      },
      "cell_type": "code",
      "source": [
        "subm.loc[~subm.FVC1.isnull()].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aCxLUwVxrvE4"
      },
      "cell_type": "code",
      "source": [
        "subm.loc[~subm.FVC1.isnull(),'FVC'] = subm.loc[~subm.FVC1.isnull(),'FVC1']\n",
        "if sigma_mean<70:\n",
        "    subm['Confidence'] = sigma_opt\n",
        "else:\n",
        "    subm.loc[~subm.FVC1.isnull(),'Confidence'] = subm.loc[~subm.FVC1.isnull(),'Confidence1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "giegnNKurvE4"
      },
      "cell_type": "code",
      "source": [
        "subm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Q9oGzV9OrvE4"
      },
      "cell_type": "code",
      "source": [
        "subm.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rAEx7l0LrvE5"
      },
      "cell_type": "code",
      "source": [
        "otest = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')\n",
        "for i in range(len(otest)):\n",
        "    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'FVC'] = otest.FVC[i]\n",
        "    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'Confidence'] = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2u3bJRFTrvE5"
      },
      "cell_type": "code",
      "source": [
        "subm[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TjXSxuCbrvE5"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}